# ğŸš¢ DashLogistics Intelligence Platform

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.29+-red.svg)](https://streamlit.io)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)](https://postgresql.org)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://docker.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

![DashLogistics Banner](https://copilot.microsoft.com/th/id/BCO.41ecb967-dd6c-47b5-931b-b59f26cd1e80.png)

> **Sistema completo de Business Intelligence para anÃ¡lisis de eficiencia logÃ­stica y optimizaciÃ³n de rutas basado en datos demogrÃ¡ficos, climÃ¡ticos y de combustible.**

## ğŸ¯ **VisiÃ³n del Proyecto**

DashLogistics es una plataforma de **Data Intelligence** que combina mÃºltiples fuentes de datos para proporcionar insights accionables sobre eficiencia logÃ­stica en Estados Unidos. El proyecto demuestra capacidades end-to-end de **Data Engineering** y **Data Science**:

- **ETL Pipeline** automatizado con validaciÃ³n robusta
- **Data Enrichment** mediante APIs externas (combustible, clima)
- **Machine Learning** para predicciones de eficiencia
- **Dashboard interactivo** con visualizaciones en tiempo real
- **Arquitectura escalable** con Docker y PostgreSQL

## ğŸ—ï¸ **Arquitectura del Sistema**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   ETL Pipeline   â”‚    â”‚   Data Storage  â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Kaggle Datasetâ”‚â”€â”€â”€â–¶â”‚ â€¢ Data Cleaning  â”‚â”€â”€â”€â–¶â”‚ â€¢ PostgreSQL    â”‚
â”‚ â€¢ Fuel API      â”‚    â”‚ â€¢ Validation     â”‚    â”‚ â€¢ Master Tables â”‚
â”‚ â€¢ Weather API   â”‚    â”‚ â€¢ Enrichment     â”‚    â”‚ â€¢ Versioning    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   ML Models     â”‚    â”‚   Dashboard      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                 â”‚    â”‚                  â”‚
â”‚ â€¢ Linear Reg.   â”‚    â”‚ â€¢ Streamlit      â”‚
â”‚ â€¢ KPI Analysis  â”‚    â”‚ â€¢ Plotly Viz     â”‚
â”‚ â€¢ Predictions   â”‚    â”‚ â€¢ Real-time      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ **CaracterÃ­sticas Principales**

### ğŸ“Š **ETL Pipeline Avanzado**
- **ValidaciÃ³n de datos** con Pydantic schemas
- **Logging estructurado** con run_id Ãºnico para trazabilidad
- **Manejo robusto de errores** y reintentos automÃ¡ticos
- **Procesamiento idempotente** con SQLAlchemy

### ğŸŒ¤ï¸ **Data Enrichment**
- **Precios de combustible**: Scraping automatizado de AAA
- **Datos climÃ¡ticos**: WeatherAPI.com + OpenWeather fallback
- **IntegraciÃ³n inteligente** con detecciÃ³n de outliers

### ğŸ¤– **Machine Learning**
- **Modelos predictivos** de eficiencia logÃ­stica
- **AnÃ¡lisis de correlaciÃ³n** entre variables
- **MÃ©tricas de evaluaciÃ³n** automÃ¡ticas

### ğŸ“ˆ **Dashboard Interactivo**
- **KPIs en tiempo real** de eficiencia
- **AnÃ¡lisis geogrÃ¡fico** por estados
- **Visualizaciones interactivas** con Plotly
- **Modelado predictivo** integrado

## ğŸ› ï¸ **Stack TecnolÃ³gico**

| Componente | TecnologÃ­a | PropÃ³sito |
|------------|------------|-----------|
| **Backend** | Python 3.11+ | Core ETL y ML |
| **Base de Datos** | PostgreSQL 15 | Almacenamiento principal |
| **Dashboard** | Streamlit + Plotly | VisualizaciÃ³n interactiva |
| **APIs** | WeatherAPI, OpenWeather | Enriquecimiento de datos |
| **Scraping** | BeautifulSoup + Requests | Datos de combustible |
| **ValidaciÃ³n** | Pydantic | Calidad de datos |
| **Testing** | pytest | Calidad del cÃ³digo |
| **Container** | Docker + Docker Compose | Despliegue consistente |
| **Calidad** | Ruff, pre-commit | Linting y formateo |

## ğŸ“‹ **Requisitos Previos**

- **Python 3.11+**
- **PostgreSQL 15+** (o Docker)
- **Git** para clonar el repositorio

## âš™ï¸ **InstalaciÃ³n y ConfiguraciÃ³n**

### 1. **Clonar el Repositorio**
```bash
git clone https://github.com/juandelaf1/DashLogistics.git
cd DashLogistics
```

### 2. **Entorno Virtual**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows
```

### 3. **Dependencias**
```bash
pip install -r requirements.txt
```

### 4. **Variables de Entorno**
```bash
cp .env.example .env
# Editar .env con tus configuraciones:
# DATABASE_URL=postgresql://user:pass@localhost:5432/shipping_db
# WEATHERAPI_KEY=tu_api_key
# OPENWEATHER_API_KEY=tu_api_key_opcional
```

### 5. **Base de Datos**
```bash
# OpciÃ³n A: Docker (recomendado)
docker-compose up -d db

# OpciÃ³n B: PostgreSQL local
# Crear database 'shipping_db' y configurar conexiÃ³n en .env
```

## ğŸš€ **EjecuciÃ³n del Sistema**

### **Modo Desarrollo**
```bash
# 1. Ejecutar pipeline ETL completo
python main.py

# 2. Iniciar dashboard
streamlit run dashboard/dashboard.py
```

### **Modo ProducciÃ³n (Docker)**
```bash
# Todos los servicios
docker-compose up -d

# Acceso:
# Dashboard: http://localhost:8501
# API: http://localhost:5000
# Base de datos: localhost:5432
```

## ğŸ“Š **Uso del Dashboard**

### **PÃ¡ginas Disponibles:**

1. **ğŸ  Dashboard Principal**
   - KPIs de eficiencia logÃ­stica
   - AnÃ¡lisis de correlaciÃ³n poblaciÃ³n-ranking
   - Top/Bottom estados por eficiencia

2. **ğŸ“ˆ AnÃ¡lisis Predictivo**
   - Modelos de Machine Learning
   - MÃ©tricas de evaluaciÃ³n
   - Visualizaciones predictivas

3. **â›½ Precios Combustible**
   - AnÃ¡lisis de precios por estado
   - CorrelaciÃ³n con eficiencia logÃ­stica
   - Tendencias y variaciones

4. **ğŸŒ¤ï¸ Impacto ClimÃ¡tico**
   - Datos meteorolÃ³gicos en tiempo real
   - AnÃ¡lisis de impacto en operaciones
   - Mapas de calor climÃ¡ticos

## ğŸ§ª **Testing**

```bash
# Ejecutar todos los tests
pytest

# Con cobertura
pytest --cov=src

# Tests especÃ­ficos
pytest tests/test_etl.py
pytest tests/test_logging.py
```

## ğŸ“ **Estructura del Proyecto**

```
DashLogistics/
â”œâ”€â”€ src/                          # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ etl/                     # LÃ³gica ETL
â”‚   â”‚   â”œâ”€â”€ etl.py              # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ scrapers/           # Web scraping
â”‚   â”‚   â””â”€â”€ enrichment/         # APIs externas
â”‚   â”œâ”€â”€ database/                # ConfiguraciÃ³n BD
â”‚   â”œâ”€â”€ utils/                   # Utilidades
â”‚   â””â”€â”€ api/                     # Endpoints (futuro)
â”œâ”€â”€ dashboard/                    # Streamlit dashboard
â”œâ”€â”€ tests/                        # Suite de pruebas
â”œâ”€â”€ alembic/                      # Migraciones BD
â”œâ”€â”€ archive/                      # CÃ³digo legacy
â”œâ”€â”€ logs/                         # Logs del sistema
â””â”€â”€ docker-compose.yml           # OrquestaciÃ³n
```

## ğŸ”§ **ConfiguraciÃ³n Avanzada**

### **API Keys**
- **WeatherAPI.com** (recomendado): 1M llamadas/mes gratis
- **OpenWeather**: 60 llamadas/minuto gratis
- Configurar ambas para fallback automÃ¡tico

### **Base de Datos**
- **ProducciÃ³n**: Configurar connection pooling
- **Testing**: Base de datos separada
- **Backups**: Automatizados con pg_dump

### **Logging**
- **Niveles**: DEBUG, INFO, WARNING, ERROR
- **Destinos**: Archivo rotativo + consola
- **Trazabilidad**: run_id Ãºnico por ejecuciÃ³n

## ğŸ“ˆ **MÃ©tricas y KPIs**

### **KPIs Principales:**
- **Ãndice Eficiencia**: `population_per_rank`
- **Costo-eficiencia**: `pop_per_dollar`
- **Impacto climÃ¡tico**: correlaciÃ³n temperatura-eficiencia
- **Variabilidad**: desviaciÃ³n estÃ¡ndar por regiÃ³n

### **Modelos ML:**
- **RegresiÃ³n Lineal**: predicciÃ³n de ranking
- **RÂ² Score**: evaluaciÃ³n de ajuste
- **MSE**: error cuadrÃ¡tico medio

## ğŸš€ **Roadmap Futuro**

### **Short Term (PrÃ³ximas 2 semanas)**
- [ ] Integrar mÃ¡s variables climÃ¡ticas
- [ ] AÃ±adir tests de integraciÃ³n
- [ ] Optimizar queries de base de datos

### **Medium Term (PrÃ³ximo mes)**
- [ ] API REST completa con FastAPI
- [ ] Sistema de alertas automÃ¡ticas
- [ ] IntegraciÃ³n con mÃ¡s datasets

### **Long Term (PrÃ³ximos 3 meses)**
- [ ] Machine Learning avanzado (Random Forest, XGBoost)
- [ ] Sistema de recomendaciÃ³n de rutas
- [ ] Dashboard mÃ³vil responsive

## ğŸ¤ **Contribuciones**

Las contribuciones son bienvenidas. Por favor:

1. Fork del repositorio
2. Crear feature branch (`git checkout -b feature/amazing-feature`)
3. Commit cambios (`git commit -m 'Add amazing feature'`)
4. Push al branch (`git push origin feature/amazing-feature`)
5. Abrir Pull Request

## ğŸ“ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ‘¨â€ğŸ’» **Autor**

**Juan M. de la Fuente Larrocca**
- Data Analyst & Data Engineer
- Madrid, EspaÃ±a
- [GitHub](https://github.com/juandelaf1)
- [LinkedIn](https://linkedin.com/in/juandelaf1)

## ğŸ™ **Agradecimientos**

- **Kaggle** por datasets demogrÃ¡ficos
- **WeatherAPI.com** por API climÃ¡tica generosa
- **AAA** por datos de precios de combustible
- **Streamlit** por framework de dashboard increÃ­ble

---

<div align="center">

**ğŸš¢ DashLogistics - Transformando datos en inteligencia logÃ­stica ğŸš¢**

*Built with â¤ï¸ using Python, Streamlit & PostgreSQL*

</div>
